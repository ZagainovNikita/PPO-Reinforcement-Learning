{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import Env\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "from model import ConvolutionalNN, FeedForwardNN\n",
    "from ppo import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvolutionalNN((210, 160, 3), 4).to(torch.device(\"cuda:0\"))\n",
    "inputs = torch.randint(low=0, high=255, size=(10, 210, 160, 3), device=torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.mse_loss(outputs, torch.rand_like(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Edu\\python_projects\\reinforcement_learning\\.venv\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Edu\\python_projects\\reinforcement_learning\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.0681e-03, -5.3894e-03, -5.2467e-03, -4.3505e-03],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 2.7045e-07,  4.4533e-07,  3.3775e-07,  4.5090e-07],\n",
       "        [ 1.4061e-03,  1.2062e-03,  9.3364e-04,  2.5658e-03],\n",
       "        [-9.5730e-04, -6.5352e-04, -8.5811e-04, -3.5806e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-4.1581e-03, -2.7064e-03, -3.4125e-03, -3.4322e-03],\n",
       "        [-9.0441e-04, -6.7664e-04,  7.9219e-05, -4.0929e-04],\n",
       "        [-6.1115e-03, -7.7208e-03, -8.3584e-03, -8.5151e-03],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-7.8143e-03, -5.3445e-03, -7.8106e-03, -8.1904e-03],\n",
       "        [ 1.0604e-05, -4.1872e-05,  9.0837e-07, -3.2192e-05],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.0629e-05,  9.2522e-05,  1.1633e-05,  6.3653e-05],\n",
       "        [-6.8611e-06, -4.4977e-06, -5.1835e-05, -5.6333e-05],\n",
       "        [-2.5924e-03, -3.3822e-03, -2.4482e-03, -1.7120e-03],\n",
       "        [ 2.5996e-03,  3.9448e-03,  1.9144e-03,  4.5269e-04],\n",
       "        [ 1.7777e-04,  5.0214e-05,  2.4337e-04,  4.8491e-05],\n",
       "        [ 3.0699e-03,  2.7294e-03,  1.0257e-03,  5.1063e-04],\n",
       "        [-7.4559e-04, -8.6921e-04, -5.9784e-04, -1.4118e-03],\n",
       "        [ 3.6810e-03,  4.8376e-03,  3.5300e-03,  5.0777e-03],\n",
       "        [-4.5033e-03, -4.3654e-03, -3.2697e-03, -3.0163e-03],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-6.3538e-04, -5.7524e-04, -2.2209e-04, -2.1189e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 2.5243e-03,  2.9486e-03,  3.8716e-03,  2.9432e-03],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 4.8567e-06,  1.2673e-05,  1.4159e-05, -6.4801e-06],\n",
       "        [-3.2851e-04,  9.5740e-05, -1.2773e-04,  3.4517e-04],\n",
       "        [-9.8334e-03, -1.1030e-02, -1.0427e-02, -9.6505e-03],\n",
       "        [ 1.9870e-05,  1.2802e-05,  1.7270e-06,  1.1062e-05],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-5.5253e-03, -6.9262e-03, -6.6556e-03, -6.0953e-03],\n",
       "        [ 9.4142e-05,  1.0445e-05,  4.8704e-06,  9.3951e-05],\n",
       "        [ 1.5036e-03, -3.8452e-04,  5.8888e-04,  1.3292e-03],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 2.9880e-04,  1.9638e-04,  5.9214e-04,  1.1134e-03],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.2083e-02,  1.1804e-02,  1.2814e-02,  1.4013e-02],\n",
       "        [ 1.1161e-02,  1.0537e-02,  1.0038e-02,  1.1279e-02],\n",
       "        [-5.7754e-03, -5.7820e-03, -4.9094e-03, -6.0044e-03],\n",
       "        [-4.2934e-03, -5.7034e-03, -5.2448e-03, -7.2807e-03],\n",
       "        [-3.4639e-03, -4.4275e-03, -2.1762e-03, -3.6111e-03],\n",
       "        [ 6.3287e-03,  4.3543e-03,  6.2953e-03,  6.4964e-03],\n",
       "        [ 6.4758e-04,  8.8268e-04,  5.2713e-06,  4.7088e-04],\n",
       "        [ 7.9852e-03,  7.7716e-03,  6.0763e-03,  8.7271e-03],\n",
       "        [ 1.5431e-03,  4.1331e-04,  2.1877e-03,  1.6801e-03],\n",
       "        [ 1.1623e-03,  2.4984e-03,  1.0430e-03,  2.5487e-03],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 3.4254e-03,  3.6699e-03,  2.1250e-03,  5.1809e-03],\n",
       "        [ 1.9569e-05, -4.2840e-04, -1.5098e-03, -1.6678e-03],\n",
       "        [ 1.1229e-03,  1.1577e-03, -1.2905e-03, -3.3892e-04],\n",
       "        [-1.8555e-02, -1.8874e-02, -1.7502e-02, -1.7947e-02],\n",
       "        [ 1.1218e-02,  1.0413e-02,  1.1058e-02,  1.2248e-02],\n",
       "        [-7.5092e-04, -4.2673e-04, -3.8519e-04, -2.4924e-04],\n",
       "        [ 9.7446e-03,  9.3325e-03,  7.3003e-03,  1.0715e-02],\n",
       "        [-1.3664e-02, -1.2183e-02, -1.1833e-02, -1.1732e-02],\n",
       "        [-7.1727e-03, -5.1121e-03, -8.1922e-03, -7.7955e-03],\n",
       "        [ 8.0128e-04,  1.4052e-03,  1.9229e-03,  6.8013e-04],\n",
       "        [-1.4668e-02, -1.3855e-02, -1.1678e-02, -1.2898e-02],\n",
       "        [ 7.7530e-04,  2.3743e-04,  1.7152e-04,  2.9522e-04],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 5.1377e-03,  2.1208e-03,  4.8412e-03,  5.1336e-03],\n",
       "        [ 4.8069e-04,  9.4251e-05,  3.2890e-04,  9.7500e-05]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
